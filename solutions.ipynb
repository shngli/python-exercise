{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79a21d13",
   "metadata": {},
   "source": [
    "## Q1) Vector compression\n",
    "\n",
    "You want to compress an array that often contains consecutive appearances of the same integer. The task is to reduce the array into a compressed array that contains, one after the other, the integer seen and the number of consecutive repetitions of that integer.\n",
    "\n",
    "```\n",
    "Input: arr = [1,1,1,5,3,3,9,3,3,3,3,3]\n",
    "Output: [1,3,5,1,3,2,9,1,3,5]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b10a5a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "def compress(a):\n",
    "    list1 = a\n",
    "    \n",
    "    # remove consecutive duplicates and keep the sequence\n",
    "    # [1,1,1,5,3,3,9,3,3,3,3,3] -> [1, 5, 3, 9, 3]\n",
    "    lst1 = [i[0] for i in groupby(list1)]\n",
    "    \n",
    "    # count consecutive duplicates in list\n",
    "    # [1,1,1,5,3,3,9,3,3,3,3,3] -> [3, 1, 2, 1, 5]\n",
    "    lst2 = [sum(1 for _ in group) for _, group in groupby(list1)]\n",
    "    \n",
    "    # merge 2 lists alternatively\n",
    "    merge_list = [sub[item] for item in range(len(lst2)) for sub in [lst1, lst2]]\n",
    "    \n",
    "    return merge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdf804a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 5, 1, 3, 2, 9, 1, 3, 5]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = [1,1,1,5,3,3,9,3,3,3,3,3]\n",
    "compress(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab042686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88d6bb28",
   "metadata": {},
   "source": [
    "## Q2) Cross-validation\n",
    "\n",
    "Given a list L of values generated independently by some unknown process, we will use the mean of L to predict unseen values generated by the same process. Use leave-one-out cross-validation to estimate the mean absolute error of this process.\n",
    "\n",
    "```\n",
    "- Input: An array of floats arr\n",
    "- Output: A float score\n",
    "\n",
    "Example:\n",
    "- arr = [1 2 3]\n",
    "- score = 1.0\n",
    "\n",
    "Explanation:\n",
    "1. Leave 1 out:\n",
    "    - Mean = (2+3)/2 = 2.5\n",
    "    - MAE = 2.5 - 1 = 1.5\n",
    "   \n",
    "2. Leave 2 out:\n",
    "    - Mean = (1+3)/2 = 2\n",
    "    - MAE = 2 - 2 = 0\n",
    "    \n",
    "3. Leave 3 out:\n",
    "    - Mean = (1+2)/2 = 1.5\n",
    "    - MAE = 3 - 1.5 = 1.5\n",
    "    \n",
    "Average of MAE = (1.5 + 0 + 1.5)/3 = 1.0\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e512d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def loocv(x):\n",
    "    \n",
    "    mae_list = []\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        # Leave One Out = exclude the element in the current ith position \n",
    "        y = [el for el in x if el!=x[i]]\n",
    "        \n",
    "        # get the element that is left out, convert 1-item list into integer\n",
    "        y_loo = [int(el) for el in x if el==x[i]]\n",
    "        y_true = y_loo[0]\n",
    "        #print(y_true)\n",
    "        \n",
    "        # get the average of the remaining elements in the list\n",
    "        prediction = np.mean(y)\n",
    "        \n",
    "        # MAE = average of y_true - prediction\n",
    "        mae = np.mean(np.abs(y_true - prediction))\n",
    "        \n",
    "        # append MAE to list\n",
    "        mae_list.append(mae)\n",
    "        \n",
    "    # MAE of LOOCV = average of all the MAEs in the list\n",
    "    mae_loocv = np.mean(mae_list)\n",
    "    return mae_loocv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c09e5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true = [1,2,3]\n",
    "loocv(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fcff57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f554d7ba",
   "metadata": {},
   "source": [
    "## Q3) Tokenization:\n",
    "\n",
    "Given a list of sentences:\n",
    "\n",
    "- convert words to lower case\n",
    "- tokenize the words by white space\n",
    "- convert to word matrix, ordered by alphabetical order\n",
    "\n",
    "```\n",
    "Input: ['This is ball','My ball','This is cat Cat']\n",
    "Output: [[1 0 1 0 1], [1 0 0 1 0], [0 2 1 0 1]] \n",
    "\n",
    "               ball, cat, is, my, this\n",
    "sentence 1:    1     0    1   0   1\n",
    "sentence 2:    1     0    0   1   0\n",
    "sentence 3:    0     2    1   0   1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c4736c",
   "metadata": {},
   "source": [
    "### Solution 1: Custom count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fee0d6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections import Counter\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def custom_fit(a):\n",
    "    \n",
    "    # convert words to lower case and split by white space\n",
    "    # sort each word within the list alphabetically\n",
    "    res = [sorted(sub.lower().split()) for sub in a]\n",
    "    \n",
    "    # bag of words = merge list of strings and sort alphabetically\n",
    "    bow = sorted(list(set(itertools.chain.from_iterable(res))))\n",
    "    #print(bow) \n",
    "    \n",
    "    # get word index position from bag of words list\n",
    "    vocab = {}\n",
    "    for index, word in enumerate(bow):\n",
    "        vocab[word] = index    \n",
    "    print('bag of words:', vocab)\n",
    "    \n",
    "    # create empty lists to store sparse matrix\n",
    "    row, col, val = [],[],[]\n",
    "    \n",
    "    for idx, sentence in enumerate(text):\n",
    "        # count number words in each sentence\n",
    "        count_word = dict(Counter(sentence.lower().split()))\n",
    "        \n",
    "        for word, count in count_word.items():\n",
    "            # get the index of each word from bag of words\n",
    "            col_index = vocab.get(word)\n",
    "            \n",
    "            if col_index >= 0:\n",
    "                row.append(idx)\n",
    "                col.append(col_index)\n",
    "                val.append(count)\n",
    "    \n",
    "    word_matrix = (csr_matrix((val, (row,col)), shape=(len(text),len(vocab)))).toarray()\n",
    "    return word_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a1db5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of words: {'ball': 0, 'cat': 1, 'is': 2, 'my': 3, 'this': 4}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 0, 1],\n",
       "       [1, 0, 0, 1, 0],\n",
       "       [0, 2, 1, 0, 1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ['This is ball','My ball','This is cat Cat']\n",
    "custom_fit(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba286984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99311ac4",
   "metadata": {},
   "source": [
    "### Solution 2: With SKLearn count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a97ef796",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def token_sk(a):\n",
    "    \n",
    "    # convert words to lower case\n",
    "    res = [sub.lower() for sub in a]\n",
    "    \n",
    "    # create a Vectorizer Object \n",
    "    vectorizer = CountVectorizer()\n",
    "    vectorizer.fit(res)\n",
    "    \n",
    "    # printing the identified unique words along with their indices\n",
    "    print(\"Vocabulary: \", vectorizer.vocabulary_)\n",
    "    \n",
    "    # encode the document\n",
    "    vector = vectorizer.transform(res)\n",
    "    print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89d38952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:  {'this': 4, 'is': 2, 'ball': 0, 'my': 3, 'cat': 1}\n",
      "[[1 0 1 0 1]\n",
      " [1 0 0 1 0]\n",
      " [0 2 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "text = ['This is ball','My ball','This is cat Cat']\n",
    "token_sk(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5023694c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bb2d156",
   "metadata": {},
   "source": [
    "---------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
